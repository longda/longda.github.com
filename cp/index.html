---
layout: dcc
---

<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
<style>
  body { font-family: 'Open Sans', sans-serif; }
  .videoWrapper {
	position: relative;
	padding-bottom: 56.25%; /* 16:9 */
	padding-top: 25px;
	height: 0;
}
.videoWrapper iframe {
	position: absolute;
	top: 0;
	left: 0;
	width: 100%;
	height: 100%;
}
</style>

<main>
  <div class="pl-2 pr-2 column pt-6">
    <h1 class="h2">Computational Photography</h1>
    <h2 class="h3"></h2>

    <h2 class="h3">Final Project: Tiny Planets</h2>
    <img src="img/coachella_astronaut.jpg" alt title="Coachella Astronaut Original">
    <div class="pb-6 gap"></div>
    <img src="img/input_03.jpg" alt title="Coachella Astronaut Mirrored">
    <div class="pb-6 gap"></div>
    <img src="img/output_03.jpg" alt title="Coachella Astronaut Tiny Planet">
    <div class="pb-6 gap"></div>

    <p>
      For a final project, I decided to implement a <a href="https://www.lrde.epita.fr/~adl/dl/adl/german.07.cae.pdf">Tiny Planet</a> computational photography pipeline.
    </p>
    <p>
      This <a href="https://petapixel.com/2013/08/17/how-to-turn-a-smartphone-panorama-into-a-tiny-planet-photo/">pipeline</a> involves a few pre-processing steps to optionally mirror, flip, and/or square the input image.
    </p>
    <p>
      An output image is prepared and inverse warping is used to compute what pixels to pull from the input image.
    </p>
    <p>
      Conceptually, this technique is based on <a href="https://en.wikipedia.org/wiki/Stereographic_projection#Photography">stereographic projection</a> and is heavily dependent on <a href="https://physicsandphotography.wordpress.com/2014/12/18/tiny-planet-calculations/">trigonometry</a>.
    </p>
    <p>
      Ideally, I'd like to implement this pipeline in an iPhone app so I can take advantage of the onboard cameras and built in software.
    </p>

    <img src="img/output_06.jpg" alt title="Coachella Butterfly Tiny Planet">
    <div class="pb-6 gap"></div>
    <img src="img/output_04.jpg" alt title="Coachella Palm Trees Inverted Tiny Planet">
    <div class="pb-6 gap"></div>
    <img src="img/output_02.jpg" alt title="Coachella Sunset Tiny Planet">


    <h2 class="h3">Epsilon Photography</h2>
    <img src="img/epsilon_01.png" alt title="Epsilon Photo Ingredients">
    <div class="pb-6 gap"></div>
    <a href="/images/gt/lights_01.gif"><img src="/images/gt/lights_01_crunched.gif" alt title="LAX Pylon Project Small"></a>
    <p>
      <a href="https://en.wikipedia.org/wiki/Epsilon_photography">Epsilon photography</a> is the process of capturing multiple images in sequence while
      slightly varying one parameter such as exposure, focus, or aperture.
    </p>
    <p>
      In this project, I took time sequence photographs of Pylon #0 at the LAX Kinetic Light art installation at Los Angeles International Airport by mounting
      a flexible tripod on a nearby valve system and firing the shutter using a remote.
    </p>
    <p>
      The final artifact is animate gif combining 40 images take from the base of the pylon taken manually over the course of about 15 minutes.
    </p>

    <h2 class="h3">Camera Obscura</h2>
    <img src="img/camera_obscura_01.png" alt title="Camera Obscura Ingredients">
    <div class="pb-6 gap"></div>
    <img src="img/camera_obscura_output.jpg" alt title="Camera Obsccura Result">
    <p>
      The <a href="https://en.wikipedia.org/wiki/Camera_obscura">camera obscura</a> is the foundational concept for how modern cameras and even human eyes capture light and form images.
    </p>
    <p>
      For this project, I recreated this technique in a studio apartment and captured a nearby sand dune scene.
    </p>
    <p>
      As a reference, I visited a variety of <a href="http://www.griffithobservatory.org/exhibits/halloftheeye_cameraobscura.html">local</a> camera <a href="https://www.atlasobscura.com/places/camera-obscura-santa-monica">obscura</a> installations around Los Angeles as well as an <a href="http://www.abelardomorell.net/project/tent-camera/">Abelardo Morell</a> exhibit.
    </p>

    <h2 class="h3">Blending</h2>
    <img src="img/blending_01.png" alt title="Blending Ingredients">
    <div class="pb-6 gap"></div>
    <img src="img/blending_output.png" alt title="Blending Result :: Little Rocket Man">
    <div class="pb-6 gap"></div>
    <img src="img/blending_02.png" alt title="Blending Fun Results">
    <p>
      The code is based on a concept called <a href="https://en.wikipedia.org/wiki/Pyramid_%28image_processing%29">"image pyramids"</a> which are used in a wide variety of applications such as computer vision (<a href="https://en.wikipedia.org/wiki/Optical_flow">optical flow</a>), image processing (blending), and even image compression.
    </p>
    <p>
      After a tiny bit of research, I also found out it's used as the basis for <a href="https://en.wikipedia.org/wiki/Mipmap">mipmaps</a>, a common technique used in games and simulations for texturing because it can speed up rendering and reduce artifacts such as aliasing.  As an example, mipmaps are a <a href="https://docs.unity3d.com/Manual/class-TextureImporter.html">feature</a> of Unity3D and other game engines.
    </p>
    <p>
      At its core, the technique creates two sets of image pyramids: Gaussians and Laplacians.
    </p>
    <p>
      Gaussians are based on the original image and each level is weighted and subsampled version of the preceding layer, producing further pixelated versions at each level.
    </p>
    <p>
      Laplacians are generated by subtracting Gaussians at adjacent levels, creating differential images aka difference of Gaussians.
    </p>
    <p>
      The top level of the Laplacian pyramid is the same as the Gaussian pyramid, a very pixelated version of the original image.
    </p>
    <p>
      By expanding and adding layer of the Laplacian, you can get back to the original image, hence the reason this technique is leveraged for image compression and mip maps.
    </p>
    <p>
      Additionally, there is an added blend step in this pipeline which uses a grayscale mask to blend images at each level of the pyramid before expanding the result.
    </p>
    <p>
      This creates a better final product as the blend is done at multiple layers and frequencies, rather than just the full resolution image.
    </p>
    <p>
      For example, this technique is used in professional image processing software, such as Photoshop.
    </p>
    <p>
      This technique is largely based on the commonly cited paper from the 1980s: Burt and Adelson, “A multiresolution spline with application to image mosaics”. In ACM Transactions on Graphics, 2 (4). 1983.
    </p>


    <h2 class="h3">Panoramas</h2>
    <img src="img/pano_01.jpg" alt title="Panorama 1 Result">
    <div class="pb-6 gap"></div>
    <img src="img/pano_02.jpg" alt title="Panorama 2 Result">
    <div class="pb-6 gap"></div>
    <img src="img/pano_03.jpg" alt title="Panorama 3 Result">

    <h2 class="h3">HDR</h2>
    <img src="img/hdr_01.png" alt title="HDR Ingredients">
    <div class="pb-6 gap"></div>
    <img src="img/hdr_output.png" alt title="HDR Result">

    <h2 class="h3">Video Textures</h2>
    <img src="img/video_texture_01.png" alt title="Video Texture Energy">


    <h2 class="h3">Midterm Project: Seam Carving</h2>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/dSys95N-5Gw?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>
    <div class="pb-6 gap"></div>
    <img src="img/seam_carving_total_energy.png" alt title="Seam Carving Total Energy">
    <div class="pb-6 gap"></div>
    <img src="img/seam_carving_01.png" alt title="Seam Carving :: Seam to Remove">


    <h2 class="h3">Drone Photography</h2>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/j2k139y-Ovc?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>
    <div class="pb-6 gap"></div>
    <img src="img/over_the_sea.jpg" alt title="Over the Sea :: Drone Shot">



    <div class="pb-6 gap"></div>
  </div>
</main>
