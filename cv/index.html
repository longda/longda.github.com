---
layout: dcc
---

<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
<style>
  body { font-family: 'Open Sans', sans-serif; }
  .videoWrapper {
	position: relative;
	padding-bottom: 56.25%; /* 16:9 */
	padding-top: 25px;
	height: 0;
}
.videoWrapper iframe {
	position: absolute;
	top: 0;
	left: 0;
	width: 100%;
	height: 100%;
}
</style>

<main>
  <div class="pl-2 pr-2 column pt-6">
    <h1 class="h2">Computer Vision</h1>
    <h2 class="h3"></h2>

    <h2 class="h3">Final Project: Enhanced Augmented Reality</h2>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/ZFQBjU5WYE0?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>
    <p>
      For this project, students were required to create a simple markerless augmented reality system, similar to the assignment below, but without the
      corner markers and produce a white paper detailing our experiences with the technique.
    </p>
    <p>
      To accomplish this task, I used an image tracker system which uses a combination of image recognition to identify a target
      and then search through input frames for positive identification.
    </p>
    <p>
      Each frame, a number of steps are completed including feature extraction and matching, homography estimation and refinement, and pose estimation
      based on a known camera calibration.
    </p>
    <p>
      A few of the computer vision methods used in the project are ORB feature detection, KNN feature matching using a brute force matcher with cross correlation,
      homography estimation using RANSAC, SolvePNP() with Levenberg-Marquardt optimization, and conversion of the rotation matrix to a vector using
      Rodrigues.
    </p>
    <p>
      <strong>Algorithms: </strong><a href="https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_feature2d/py_orb/py_orb.html">ORB</a>,
      <a href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_matcher/py_matcher.html">BF Matcher</a>,
      <a href="https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_ml/py_knn/py_knn_understanding/py_knn_understanding.html">KNN Matching</a>,
      <a href="https://en.wikipedia.org/wiki/Random_sample_consensus">RANSAC</a>,
      <a href="https://www.learnopencv.com/homography-examples-using-opencv-python-c/">findHomography</a>,
      <a href="https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html">warpPerspective</a>,
      <a href="https://www.pyimagesearch.com/2014/05/05/building-pokedex-python-opencv-perspective-warping-step-5-6/">perspectiveTransform</a>,
      <a href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_calib3d/py_calibration/py_calibration.html">camera calibration</a>,
      <a href="https://www.learnopencv.com/head-pose-estimation-using-opencv-and-dlib/">pose estimation</a>,
      <a href="https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html">solvePNP</a>,
      <a href="https://en.wikipedia.org/wiki/Rodrigues%27_rotation_formula">Rodrigues</a>
    </p>
    <p>
      <strong>Papers: </strong><a href="http://www.cs.zju.edu.cn/~gpan/course/materials/ORB.pdf">ORB: an efficient alternative to SIFT or SURF (2011)</a>,
      <a href="http://www.dtic.mil/dtic/tr/fulltext/u2/a460585.pdf">Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography (1980)</a>
    </p>
    <!-- <p>

    </p> -->


    <h2 class="h3">Augmented Reality</h2>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/Ko6mpTmPeA8?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>

    <p>
      In this project, students were required to build a basic augmented reality system using corner markers and handle some real life cases such as
      camera rotation/skew as well as video artifacts and noise.
    </p>
    <p>
      To start, we injected basic still frames into the video with a calculated homography to ensure the process worked correctly but the
      extra credit version extended this technique by interleaving frames from a video into the marker locations.
    </p>
    <p>
      To achieve this, I used non-local means denoising to remove any static noise and then Gaussian blurred the result to remove circle artifacts.
    </p>
    <p>
      Harris corners were used to estimate marker locations and those results were fed into KMeans with a K = 4 to identify the corners.
    </p>
    <p>
      These four points were then used to compute a homography matrix using least squares and the injected image was then inverse warped into
      the final frame to avoid holes or strange artifacts in the output.
    </p>
    <p>
      <strong>Algorithms: </strong><a href="https://docs.opencv.org/3.3.1/d5/d69/tutorial_py_non_local_means.html">Fast non-local means denoising</a>,
      <a href="https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_filtering/py_filtering.html">median blur</a>,
      <a href="https://docs.opencv.org/2.4/doc/tutorials/imgproc/gausian_median_blur_bilateral_filter/gausian_median_blur_bilateral_filter.html">gaussian blur</a>,
      <a href="https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.html">dilate</a>,
      <a href="https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_feature2d/py_features_harris/py_features_harris.html">Harris Corners</a>,
      <a href="https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_ml/py_kmeans/py_kmeans_opencv/py_kmeans_opencv.html">kmeans</a>,
      <a href="https://github.com/jmlipman/LAID/blob/master/IP/homography.py">homography estimation</a>,
      <a href="https://en.wikipedia.org/wiki/Corner_detection">corner detection</a>
    </p>
    <p><strong>Papers: </strong><a href="http://www.bmva.org/bmvc/1988/avc-88-023.pdf">A Combined Corner and Edge Detector (1988)</a>
    </p>


    <div class="pb-6 gap"></div>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/68OAv5YIVHU?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>

    <div class="pb-6 gap"></div>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/7MdcKajMC0c?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>

    <div class="pb-6 gap"></div>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/lYPsG3yas9M?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>

    <div class="pb-6 gap"></div>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/uf29LEWjIo4?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>


    <h2 class="h3">Motion Detection and Optical Flow</h2>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/sFW1ujvt6ms?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>

    <div class="pb-6 gap"></div>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/-_5TUiOtAjs?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>

    <p>
      In this assignment we implemented standard and hierarchical versions of optical flow using image pyramids, based on the Lucas Kanade
      algorithm and papers.
    </p>
    <p>
      For extra credit, we visualized the algorithm results with quiver plots overlayed on video frames.
    </p>
    <p>
      <strong>Algorithms: </strong><a href="https://docs.opencv.org/3.0.0/d2/d2c/tutorial_sobel_derivatives.html">Sobel</a>,
      <a href="https://en.wikipedia.org/wiki/Sobel_operator">Sobel Operator</a>,
      <a href="https://docs.opencv.org/3.3.1/d7/d8b/tutorial_py_lucas_kanade.html">Optical Flow</a>,
      <a href="https://en.wikipedia.org/wiki/Lucas%E2%80%93Kanade_method">Hierarchical Lucas Kanade</a>
    </p>


    <h2 class="h3">Traffic Lights and Signs</h2>
    <p>
      For the traffic light project, students were tasked with detecting traffic lights and signs in simulated images.  Later, these detectors
      were used with real images to evaulate their efficacy in real world scenarios.
    </p>
    <p>
      <strong>Algorithms: </strong><a href="https://docs.opencv.org/3.4.0/d9/db0/tutorial_hough_lines.html">Hough Lines</a>,
      <a href="https://docs.opencv.org/3.1.0/d6/d10/tutorial_py_houghlines.html">Hough Lines Probablistic</a>,
      <a href="https://docs.opencv.org/3.1.0/d4/d70/tutorial_hough_circle.html">Hough Circles</a>,
      <a href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_canny/py_canny.html">Canny Edge Detection</a>,
      <a href="https://en.wikipedia.org/wiki/Hough_transform">Hough Transform</a>
    </p>


    <h2 class="h3">Object Tracking and Pedestrian Detection</h2>
    <p>
      In this project, a variety of scenarios were presented for students to track pedestrians on the street and detect patches in presidential
      debates captured from TV.
    </p>
    <p>
      <strong>Algorithms: </strong><a href="http://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/">Kalman Filter</a> |
      <a href="https://scipy-cookbook.readthedocs.io/items/KalmanFiltering.html">code</a>,
      <a href="https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/">Particle Filters</a> |
      <a href="https://scipy-cookbook.readthedocs.io/items/ParticleFilter.html">code</a>
    </p>


    <h2 class="h3">Classification</h2>
    <p>
      This final project implemented used a variety of techniques to detect faces in common datasets such as Yalefaces and Faces94.
    </p>
    <p>
      <strong>Algorithms: </strong><a href="https://www.learnopencv.com/principal-component-analysis/">Principal Component Analysis</a>,
      <a href="https://www.learnopencv.com/object-tracking-using-opencv-cpp-python/">Boosting</a>,
      <a href="https://docs.opencv.org/3.0.0/d7/d8b/tutorial_py_face_detection.html">Haar Features</a>,
      <a href="https://en.wikipedia.org/wiki/Viola%E2%80%93Jones_object_detection_framework">Viola Jones</a>,
      Hidden Markov Models
    </p>
    <p>
      <strong>Papers: </strong><a href="http://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf">Rapid Object Detection using a Boosted Cascade of Simple Features (2001)</a>
    </p>


    <!-- <h2 class="h3">Color Spaces</h2>
    <p>

    </p> -->


    <div class="pb-6 gap"></div>
  </div>
</main>
