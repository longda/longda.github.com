---
layout: dcc
---

<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
<style>
  body { font-family: 'Open Sans', sans-serif; }
  .videoWrapper {
	position: relative;
	padding-bottom: 56.25%; /* 16:9 */
	padding-top: 25px;
	height: 0;
}
.videoWrapper iframe {
	position: absolute;
	top: 0;
	left: 0;
	width: 100%;
	height: 100%;
}
</style>

<main>
  <div class="pl-2 pr-2 column pt-6">
    <h1 class="h2">Computer Vision</h1>
    <h2 class="h3"></h2>

    <h2 class="h3">Final Project: Enhanced Augmented Reality</h2>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/ZFQBjU5WYE0?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>
    <p>
      For this project, students were required to create a simple markerless augmented reality system, similar to the assignment below, but without the
      corner markers and produce a white paper detailing our experiences with the technique.
    </p>
    <p>
      To accomplish this task, I used an image tracker system which uses a combination of image recognition to identify a target
      and then search through input frames for positive identification.
    </p>
    <p>
      Each frame, a number of steps are completed including feature extraction and matching, homography estimation and refinement, and pose estimation
      based on a known camera calibration.
    </p>
    <p>
      A few of the computer vision methods used in the project are ORB feature detection, KNN feature matching using a brute force matcher with cross correlation,
      homography estimation using RANSAC, SolvePNP() with Levenberg-Marquardt optimization, and conversion of the rotation matrix to a vector using
      Rodrigues.
    </p>
    <p>
      <strong>Algorithms: </strong><a href="https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_feature2d/py_orb/py_orb.html">ORB</a>,
      <a href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_matcher/py_matcher.html">BF Matcher</a>,
      <a href="https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_ml/py_knn/py_knn_understanding/py_knn_understanding.html">KNN Matching</a>,
      <a href="https://en.wikipedia.org/wiki/Random_sample_consensus">RANSAC</a>,
      <a href="https://www.learnopencv.com/homography-examples-using-opencv-python-c/">findHomography</a>,
      <a href="https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html">warpPerspective</a>,
      <a href="https://www.pyimagesearch.com/2014/05/05/building-pokedex-python-opencv-perspective-warping-step-5-6/">perspectiveTransform</a>,
      <a href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_calib3d/py_calibration/py_calibration.html">camera calibration</a>,
      <a href="https://www.learnopencv.com/head-pose-estimation-using-opencv-and-dlib/">pose estimation</a>,
      <a href="https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html">solvePNP</a>,
      <a href="https://en.wikipedia.org/wiki/Rodrigues%27_rotation_formula">Rodrigues</a>
    </p>
    <p>
      <strong>Papers: </strong><a href="http://www.cs.zju.edu.cn/~gpan/course/materials/ORB.pdf">ORB: an efficient alternative to SIFT or SURF</a>,
      <a href="http://www.dtic.mil/dtic/tr/fulltext/u2/a460585.pdf">Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography</a>

    </p>
    <!-- <p>

    </p> -->


    <h2 class="h3">Augmented Reality</h2>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/Ko6mpTmPeA8?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>

    <p>
      In this project, students were required to build a basic augmented reality system using corner markers and handle some real life cases such as
      camera rotation/skew as well as video artifacts and noise.
    </p>
    <p>
      To start, we injected basic still frames into the video with a calculated homography to ensure the process worked correctly but the
      extra credit version extended this technique by interleaving frames from a video into the marker locations.
    </p>
    <p>
      To achieve this, I used non-local means denoising to remove any static noise and then Gaussian blurred the result to remove circle artifacts.
    </p>
    <p>
      Harris corners were used to estimate marker locations and those results were fed into KMeans with a K = 4 to identify the corners.
    </p>
    <p>
      These four points were then used to compute a homography matrix using least squares and the injected image was then inverse warped into
      the final frame to avoid holes or strange artifacts in the output.
    </p>

    <div class="pb-6 gap"></div>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/68OAv5YIVHU?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>

    <div class="pb-6 gap"></div>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/7MdcKajMC0c?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>

    <div class="pb-6 gap"></div>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/lYPsG3yas9M?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>

    <div class="pb-6 gap"></div>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/uf29LEWjIo4?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>


    <h2 class="h3">Optical Flow</h2>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/sFW1ujvt6ms?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>

    <div class="pb-6 gap"></div>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/-_5TUiOtAjs?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>

    <p>
      In this assignment we implemented standard and hierarchical versions of optical flow using image pyramids, based on the Lucas Kanade
      algorithm and papers.
    </p>
    <p>
      For extra credit, we visualized the algorithm results with quiver plots overlayed on video frames.
    </p>


    <h2 class="h3">Traffic Lights and Signs</h2>

    <h2 class="h3">Object Tracking and Pedestrian Detection</h2>

    <h2 class="h3">Classification</h2>


    <div class="pb-6 gap"></div>
  </div>
</main>
