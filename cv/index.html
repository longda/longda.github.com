---
layout: dcc
---

<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
<style>
  body { font-family: 'Open Sans', sans-serif; }
  .videoWrapper {
	position: relative;
	padding-bottom: 56.25%; /* 16:9 */
	padding-top: 25px;
	height: 0;
}
.videoWrapper iframe {
	position: absolute;
	top: 0;
	left: 0;
	width: 100%;
	height: 100%;
}
</style>

<main>
  <div class="pl-2 pr-2 column pt-6">
    <h1 class="h2">Computer Vision</h1>
    <h2 class="h3"></h2>

    <h2 class="h3">Final Project: Enhanced Augmented Reality</h2>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/ZFQBjU5WYE0?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>
    <p>
      For this project, students were required to create a simple markerless augmented reality system, similar to the assignment below, but without the
      corner markers and produce a white paper detailing our experiences with the technique.
    </p>
    <p>
      To accomplish this task, I used an image tracker system which uses a combination of image recognition to identify a target
      and then search through input frames for positive identification.
    </p>
    <p>
      Each frame, a number of steps are completed including feature extraction and matching, homography estimation and refinement, and pose estimation
      based on a known camera calibration.
    </p>
    <p>
      A few of the computer vision methods used in the project are ORB feature detection, KNN feature matching using a brute force matcher with cross correlation,
      homography estimation using RANSAC, SolvePNP() with Levenberg-Marquardt optimization, and conversion of the rotation matrix to a vector using
      Rodrigues.
    </p>
    <!-- <p>

    </p> -->


    <h2 class="h3">Augmented Reality</h2>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/Ko6mpTmPeA8?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>

    <p>
      In this project, students were required to build a basic augmented reality system using corner markers and handle some real life cases such as
      camera rotation/skew as well as video artifacts and noise.
    </p>
    <p>
      To start, we injected basic still frames into the video with a calculated homography to ensure the process worked correctly but the
      extra credit version extended this technique by interleaving frames from a video into the marker locations.
    </p>
    <p>
      To achieve this, I used non-local means denoising to remove any static noise and then Gaussian blurred the result to remove circle artifacts.
    </p>
    <p>
      Harris corners were used to estimate marker locations and those results were fed into KMeans with a K = 4 to identify the corners.
    </p>
    <p>
      These four points were then used to compute a homography matrix using least squares and the injected image was then inverse warped into
      the final frame to avoid holes or strange artifacts in the output.
    </p>

    <div class="pb-6 gap"></div>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/68OAv5YIVHU?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>

    <div class="pb-6 gap"></div>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/7MdcKajMC0c?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>

    <div class="pb-6 gap"></div>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/lYPsG3yas9M?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>

    <div class="pb-6 gap"></div>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/uf29LEWjIo4?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>


    <h2 class="h3">Optical Flow</h2>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/sFW1ujvt6ms?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>

    <div class="pb-6 gap"></div>
    <div class="videoWrapper">
    <iframe width="640" height="360" src="https://www.youtube.com/embed/-_5TUiOtAjs?showinfo=0" frameborder="0" allowfullscreen></iframe>
    </div>

    <p>
      In this assignment we implemented standard and hierarchical versions of optical flow using image pyramids, based on the Lucas Kanade
      algorithm and papers.
    </p>
    <p>
      For extra credit, we visualized the algorithm results with quiver plots overlayed on video frames.
    </p>

    <div class="pb-6 gap"></div>
  </div>
</main>
